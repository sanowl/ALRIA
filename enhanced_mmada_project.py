#!/usr/bin/env python3
"""
Multimodal Model Demo Script
Demonstrates how to use the reorganized multimodal model package.
"""

import logging
import torch
from pathlib import Path

# Import the reorganized package
from enhanced_mmada import ModelConfig, MultimodalModel, ModelTrainer
from enhanced_mmada.config import TrainingConfig

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    """Main demo function."""
    
    logger.info("ğŸš€ Multimodal Model Demo Starting...")
    
    # 1. Initialize Configuration
    logger.info("ğŸ“‹ Initializing configuration...")
    config = ModelConfig()
    training_config = TrainingConfig()
    
    # Customize some settings for demo
    config.hidden_size = 512  # Smaller for demo
    config.num_hidden_layers = 8  # Smaller for demo
    config.save_dir = "./demo_outputs"
    training_config.num_epochs = 2  # Quick demo
    training_config.batch_size = 4
    
    logger.info(f"âœ… Model will have {config.hidden_size} hidden size, {config.num_hidden_layers} layers")
    
    # 2. Initialize Model
    logger.info("ğŸ§  Initializing multimodal model...")
    try:
        model = MultimodalModel(config)
        num_params = sum(p.numel() for p in model.parameters())
        logger.info(f"âœ… Model initialized with {num_params:,} parameters")
    except Exception as e:
        logger.error(f"âŒ Model initialization failed: {e}")
        return
    
    # 3. Test Memory Systems
    logger.info("ğŸ§  Testing memory systems...")
    try:
        # Test episodic memory
        memory_stats = model.get_memory_usage()
        logger.info(f"âœ… Memory systems initialized: {memory_stats}")
        
        # Store a demo episode
        success = model.episodic_memory.store_episode(
            context="Demo context: solving math problem",
            reasoning="Step 1: Identify the problem type. Step 2: Apply formula.",
            outcome="Successfully solved the equation",
            success_rate=0.95,
            task_type="mathematics",
            difficulty=0.7,
            metadata={"topic": "algebra", "time_taken": 30}
        )
        
        if success:
            logger.info("âœ… Successfully stored demo episode in episodic memory")
        
        # Test working memory
        model.working_memory.add_item(
            item_type="intermediate_result",
            content="x = 5",
            importance=0.8
        )
        logger.info("âœ… Added item to working memory")
        
    except Exception as e:
        logger.error(f"âŒ Memory system test failed: {e}")
    
    # 4. Initialize Trainer
    logger.info("ğŸ‹ï¸ Initializing trainer...")
    try:
        trainer = ModelTrainer(model, config, training_config)
        trainer_status = trainer.get_training_status()
        logger.info(f"âœ… Trainer initialized: {trainer_status}")
    except Exception as e:
        logger.error(f"âŒ Trainer initialization failed: {e}")
        return
    
    # 5. Test Model Forward Pass (without real data)
    logger.info("ğŸ”„ Testing model forward pass...")
    try:
        # Create dummy input
        batch_size = 2
        seq_length = 32
        vocab_size = config.vocab_size
        
        dummy_input_ids = torch.randint(0, vocab_size, (batch_size, seq_length))
        dummy_attention_mask = torch.ones_like(dummy_input_ids)
        dummy_labels = torch.randint(0, vocab_size, (batch_size, seq_length))
        
        # Forward pass
        with torch.no_grad():
            outputs = model(
                input_ids=dummy_input_ids,
                attention_mask=dummy_attention_mask,
                labels=dummy_labels
            )
        
        logger.info(f"âœ… Forward pass successful! Loss: {outputs['loss']:.4f}")
        logger.info(f"   Output shape: {outputs['logits'].shape}")
        
    except Exception as e:
        logger.error(f"âŒ Forward pass failed: {e}")
    
    # 6. Test Generation
    logger.info("ğŸ“ Testing text generation...")
    try:
        # Create dummy prompt
        prompt_ids = torch.randint(0, vocab_size, (1, 10))
        
        with torch.no_grad():
            generated = model.generate(
                input_ids=prompt_ids,
                max_length=20,
                temperature=0.8,
                do_sample=True
            )
        
        logger.info(f"âœ… Generation successful! Generated {generated.shape[1]} tokens")
        
    except Exception as e:
        logger.error(f"âŒ Generation failed: {e}")
    
    # 7. Test Configuration Serialization
    logger.info("ğŸ’¾ Testing configuration...")
    try:
        # Create output directory
        Path(config.save_dir).mkdir(parents=True, exist_ok=True)
        
        # Test model state dict
        state_dict_path = Path(config.save_dir) / "model_state.pt"
        torch.save(model.state_dict(), state_dict_path)
        logger.info(f"âœ… Model state saved to {state_dict_path}")
        
        # Test configuration
        config_info = {
            'model_parameters': num_params,
            'hidden_size': config.hidden_size,
            'num_layers': config.num_hidden_layers,
            'vocab_size': config.vocab_size,
            'device': str(model.device)
        }
        logger.info(f"âœ… Configuration: {config_info}")
        
    except Exception as e:
        logger.error(f"âŒ Configuration test failed: {e}")
    
    # 8. Display Package Structure
    logger.info("ğŸ“¦ Multimodal Model Package Structure:")
    structure = """
    enhanced_mmada/
    â”œâ”€â”€ __init__.py          # Main package exports
    â”œâ”€â”€ config.py            # Configuration classes
    â”œâ”€â”€ cli.py              # Command line interface
    â”‚
    â”œâ”€â”€ models/             # Model implementations
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ enhanced_mmada.py  # Main multimodal model
    â”‚
    â”œâ”€â”€ memory/             # Memory systems
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ episodic.py     # Episodic memory
    â”‚   â””â”€â”€ working.py      # Working memory
    â”‚
    â”œâ”€â”€ training/           # Training components
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ trainer.py      # Main trainer class
    â”‚
    â””â”€â”€ utils/              # Utilities
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ decorators.py   # Common decorators
        â””â”€â”€ text_embeddings.py
    
    Project files:
    â”œâ”€â”€ setup.py            # Package installation
    â”œâ”€â”€ requirements.txt    # Dependencies
    â”œâ”€â”€ enhanced_mmada_project.py  # This demo script
    """
    print(structure)
    
    # 9. Summary
    logger.info("ğŸ‰ Demo completed successfully!")
    logger.info("ğŸ“Š Summary:")
    logger.info(f"   â€¢ Model parameters: {num_params:,}")
    logger.info(f"   â€¢ Memory systems: Working âœ… Episodic âœ…")
    logger.info(f"   â€¢ Training pipeline: âœ…")
    logger.info(f"   â€¢ Forward pass: âœ…")
    logger.info(f"   â€¢ Text generation: âœ…")
    logger.info("")
    logger.info("ğŸ”§ Next steps:")
    logger.info("   1. Install package: pip install -e .")
    logger.info("   2. Use CLI: enhanced-mmada --help")
    logger.info("   3. Import in your code: from enhanced_mmada import *")
    logger.info("   4. Add real training data and start training!")


if __name__ == "__main__":
    main() 